{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part II: BERT\n",
    "\n",
    "Please see the description of the assignment in the README file (section 2) <br>\n",
    "**Guide notebook**: [guides/bert_guide.ipynb](guides/bert_guide.ipynb)\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "* Note that you should report results using a classification report. \n",
    "\n",
    "* Also, remember to include some reflections on your results: how do they compare with the results from Part I, BoW? Are there any hyperparameters that are particularly important?\n",
    "\n",
    "* You should follow the steps given in the `bert_guide` notebook\n",
    "\n",
    "* **Optionally**, you can fine-tune a pre-trained BERT model to classify news articles as is done in [guides/bert_guide_finetuning.ipybb](guides/bert_guide_finetuning.ipybb), the same task as in part 1. As this requires more computational resources, this part is optional. If you do decide to complete this part, you will need to use a GPU (e.g., Google Colab) to train the model. (For reference, training on a 2020 Macbook Pro with 16GB RAM and a M1 chip results in an out-of-memory error). Therefore, we suggest that you use Google Colab or another cloud-based service with a GPU. You can easily upload the `bert_guide_finetuning.ipynb` notebook to Google Colab and run it there.\n",
    "\n",
    "<br>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T18:35:03.917212Z",
     "start_time": "2025-03-30T18:34:40.008893Z"
    }
   },
   "source": [
    "# imports for the project\n",
    "\n",
    "from datasets import load_dataset, DatasetDict"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data\n",
    "\n",
    "We can load this data directly from [Hugging Face Datasets](https://huggingface.co/docs/datasets/) - The HuggingFace Hub- into a Pandas DataFrame. Pretty neat!\n",
    "\n",
    "**Note**: This cell will download the dataset and keep it in memory. If you run this cell multiple times, it will download the dataset multiple times.\n",
    "\n",
    "You are welcome to increase the `frac` parameter to load more data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T18:36:31.341440Z",
     "start_time": "2025-03-30T18:36:02.623414Z"
    }
   },
   "source": [
    "ag_news_train = load_dataset(\"fancyzhx/ag_news\", split=\"train[:20%]\")  # 20% of the training data\n",
    "ag_news_test = load_dataset(\"fancyzhx/ag_news\", split=\"test\")  # full test data\n",
    "\n",
    "ag_news = DatasetDict({\n",
    "    \"train\": ag_news_train,\n",
    "    \"test\": ag_news_test\n",
    "})\n",
    "\n",
    "ag_news"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa55ce9a267d4419819634639d02d245"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0476acdde3354103ae4761be882a4cb6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4000aa26d1d4139b1e74e50108df5ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edcc6048427047b885bfa83dbfac0987"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75e15ddc09da4ff2ac05f7c6403e7328"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 24000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Setup BERT Pipeline"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T18:42:34.271256Z",
     "start_time": "2025-03-30T18:41:14.840926Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "embedder = pipeline(\n",
    "    model=\"answerdotai/ModernBERT-base\",      # model used for embedding\n",
    "    tokenizer=\"answerdotai/ModernBERT-base\",  # tokenizer used for embedding\n",
    "    task=\"feature-extraction\",                # feature extraction task (returns embeddings)\n",
    "    device=0                                  # use GPU 0 if available\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59a3ce894bf440f19d769b41eacb498a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/599M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "071f8b2483c245269b3504df251cefde"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41fadb51f0b24184a28b8e4388307dfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.13M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21f2a125656249a0882f08b20d6a50d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8aeb4bc6502043cd968723c4bf37a702"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Encode the data"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T19:06:05.973848Z",
     "start_time": "2025-03-30T18:43:34.884774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_embeddings(data):\n",
    "    \"\"\" Extract the [CLS] embedding for each text. \"\"\"\n",
    "    embeddings = embedder(data[\"text\"])  # Full token embeddings\n",
    "    cls_embeddings = [e[0][0] for e in embeddings]  # Extract first token ([CLS])\n",
    "    return {\"embeddings\": cls_embeddings}\n",
    "\n",
    "ag_news = ag_news.map(get_embeddings, batched=True, batch_size=8)\n",
    "\n",
    "X_train = np.array(ag_news[\"train\"][\"embeddings\"])  # Feature embeddings\n",
    "y_train = np.array(ag_news[\"train\"][\"label\"])       # Labels\n",
    "\n",
    "X_test = np.array(ag_news[\"test\"][\"embeddings\"])\n",
    "y_test = np.array(ag_news[\"test\"][\"label\"])\n",
    "\n",
    "# Check shapes\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/24000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d69955bab4074fc9b766b14418ee1d3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05e1bff6febb4189bfa8e391e71c891e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (24000, 768), y_train shape: (24000,)\n",
      "X_test shape: (7600, 768), y_test shape: (7600,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Train a classifier\n",
    "We went too overboard with models in Part I: BoW, so we will keep it simple here. We will use a Logistic Regression model as a baseline and then tune it with some hyperparameters."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T19:11:59.602854Z",
     "start_time": "2025-03-30T19:10:41.123494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Baseline Logistic Regression\n",
    "lr_baseline = LogisticRegression(max_iter=2000) # Increase max_iter to avoid convergence warnings\n",
    "lr_baseline.fit(X_train, y_train)\n",
    "\n",
    "# Tuned Logistic Regression\n",
    "lr_tuned = LogisticRegression(C=0.1, max_iter=5000)\n",
    "lr_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_baseline = lr_baseline.predict(X_test)\n",
    "y_pred_tuned = lr_tuned.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"=== Baseline Model ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_baseline):.3f}\")\n",
    "print(classification_report(y_test, y_pred_baseline))\n",
    "\n",
    "print(\"\\n=== Tuned Model ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_tuned):.3f}\")\n",
    "print(classification_report(y_test, y_pred_tuned))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Model ===\n",
      "Accuracy: 0.876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      1900\n",
      "           1       0.96      0.96      0.96      1900\n",
      "           2       0.84      0.81      0.82      1900\n",
      "           3       0.82      0.87      0.84      1900\n",
      "\n",
      "    accuracy                           0.88      7600\n",
      "   macro avg       0.88      0.88      0.88      7600\n",
      "weighted avg       0.88      0.88      0.88      7600\n",
      "\n",
      "\n",
      "=== Tuned Model ===\n",
      "Accuracy: 0.878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89      1900\n",
      "           1       0.96      0.95      0.96      1900\n",
      "           2       0.84      0.81      0.83      1900\n",
      "           3       0.82      0.88      0.85      1900\n",
      "\n",
      "    accuracy                           0.88      7600\n",
      "   macro avg       0.88      0.88      0.88      7600\n",
      "weighted avg       0.88      0.88      0.88      7600\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Reflections\n",
    "\n",
    "The use of BERT with Logistic Regression as a classifier, using 20% of the training data, resulted in an accuracy of 0.876 for the baseline model and 0.878 for the tuned model. By setting C to 0.1 and max_iter to 5000, we were able to improve the accuracy slightly as it improves generalisation, but we assume the effect of the tuning would be higher if we used more of the data set than 20%.\n",
    "Regretfully as we finished Part I first without considering the potential latency of the code for Part II, it is hard to compare the results with Part I, as the model in Part I is trained with all of the data meanwhile the model in Part II is trained with only 20% of the data. But regarding performance in speed, it takes significantly longer to train the BERT model than the BoW model, with about 11 minutes for the BoW with an Apple M1 Pro chip and over 20 minutes for the BERT model with just 20% of the data. This is expected as the BERT embeddings capture richer semantic information than the BoW model, which consequently leads to higher computational costs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
